<!-- ENGLISH VERSION -->
<div class="lang-en">
    <h1>Void && Form</h1>
    <p class="cv-year">2025</p>
    <p class="cv-location">Artificial Territories Exhibition<br>Das LOT, Vienna<br>Team 망신살 (Mangshinsal)</p>
    
    <div class="image-grid" style="margin-bottom: 12px;">
        <img src="images/void/lot1.JPG" alt="Void && Form" class="grid-image" loading="lazy" onclick="openLightbox(this.src)">
        <img src="images/void/lot2.JPG" alt="Void && Form" class="grid-image" loading="lazy" onclick="openLightbox(this.src)">
        <img src="images/void/void1.JPG" alt="Void && Form" class="grid-image" loading="lazy" onclick="openLightbox(this.src)">
        <img src="images/void/void2.JPG" alt="Void && Form" class="grid-image" loading="lazy" onclick="openLightbox(this.src)">
        <img src="images/void/void3.JPG" alt="Void && Form" class="grid-image" loading="lazy" onclick="openLightbox(this.src)">
        <img src="images/void/void4.JPG" alt="Void && Form" class="grid-image" loading="lazy" onclick="openLightbox(this.src)">
        <img src="images/void/void5.JPG" alt="Void && Form" class="grid-image" loading="lazy" onclick="openLightbox(this.src)">
    </div>
    
    <p class="cv-medium">Projector, Stereo Sound, Webcam</p>
    
    <!-- Two-column grid layout starts here -->
    <div class="exhibition-content-wrapper">
        <div class="exhibition-text-column">
            <p class="exhibition-text">Void && Form, by Team Mangshinsal (Kim Hee-eun, Lee In-hye), explores how emotion recognition systems categorize human experience. When a visitor stands before the screen, FaceAPI analyzes their facial expressions in real-time and displays a graphically rendered digital twin on screen. The system categorizes detected expressions into standard emotion classifications (happiness, sadness, anger, surprise, etc.) and plays pre-composed music corresponding to each emotional state.</p>
            
            <p class="exhibition-text">The digital twin reflects the visitor's physical movements but remains separate from the lived experience generating those movements. Visitors witness the distance between what they feel and the algorithmic interpretation appearing on screen. The system reads expressions but does not understand what they mean. The face becomes data, and emotion becomes a label.</p>
            
            <p class="exhibition-text">Behind the digital twin, a mandala rotates endlessly. This rotation visualizes the continuous processing of emotional data while simultaneously revealing the instability of that processing. While the system attempts to freeze felt experience into fixed categories, the mandala's constant movement shows that emotion itself cannot be fixed. Drawing on the Buddhist concept of impermanence, this cycle suggests that meaning emerges not from static classification but from continuous change.</p>
            
            <p class="exhibition-text">The work asks: What do emotion recognition systems recognize? Is translating expressions into categories understanding or reduction? And what do we learn about ourselves when we see how algorithms see us?</p>
        </div>
        
        <div class="exhibition-image-column">
            <!-- Right column - empty for now, will contain images later -->
        </div>
    </div>
</div>

<!-- KOREAN VERSION -->
<div class="lang-kr">
    <h1>Void && Form</h1>
    <p class="cv-year">2025</p>
    <p class="cv-location">《Artificial Territories》<br>Das Lot, 비엔나, 오스트리아<br>팀 망신살</p>
    
    <div class="image-grid" style="margin-bottom: 12px;">
        <img src="images/void/lot1.JPG" alt="Void && Form" class="grid-image" loading="lazy" onclick="openLightbox(this.src)">
        <img src="images/void/lot2.JPG" alt="Void && Form" class="grid-image" loading="lazy" onclick="openLightbox(this.src)">
        <img src="images/void/void1.JPG" alt="Void && Form" class="grid-image" loading="lazy" onclick="openLightbox(this.src)">
        <img src="images/void/void2.JPG" alt="Void && Form" class="grid-image" loading="lazy" onclick="openLightbox(this.src)">
        <img src="images/void/void3.JPG" alt="Void && Form" class="grid-image" loading="lazy" onclick="openLightbox(this.src)">
        <img src="images/void/void4.JPG" alt="Void && Form" class="grid-image" loading="lazy" onclick="openLightbox(this.src)">
        <img src="images/void/void5.JPG" alt="Void && Form" class="grid-image" loading="lazy" onclick="openLightbox(this.src)">
    </div>
    
    <p class="cv-medium">Projector, Stereo Sound, Webcam</p>
    
    <!-- Two-column grid layout starts here -->
    <div class="exhibition-content-wrapper">
        <div class="exhibition-text-column">
            <p class="exhibition-text">Void && Form은 팀 망신살 (김희은, 이인혜)의 작품으로 감정 인식 시스템이 인간의 경험을 어떻게 범주화하는지 탐구한다. 관객이 스크린 앞에 서면, FaceAPI가 실시간으로 표정을 분석하고 그래픽으로 렌더링된 디지털 트윈을 화면에 보여준다. 시스템은 감지된 표정을 표준 감정 분류(행복, 슬픔, 분노, 놀람 등)로 범주화하며, 각 감정 상태에 대응하는 미리 작곡된 음악을 재생한다.</p>
            
            <p class="exhibition-text">디지털 트윈은 관객의 물리적 움직임을 반영하지만, 그 움직임을 생성하는 살아있는 경험과는 분리되어 있다. 관객은 자신이 느끼는 감정과 스크린에 나타나는 알고리즘 해석 사이의 거리를 목격한다. 시스템은 표정을 읽지만, 그것이 의미하는 바를 이해하지 못한다. 얼굴은 데이터가 되고, 감정은 라벨이 된다.</p>
            
            <p class="exhibition-text">디지털 트윈 뒤에서 만다라가 끝없이 회전한다. 이 회전은 감정 데이터의 지속적인 처리를 시각화하지만, 동시에 그 처리의 불안정성을 드러낸다. 시스템이 느껴진 경험을 고정된 범주로 동결시키려 하는 동안, 만다라의 끝없는 움직임은 감정 자체가 고정될 수 없음을 보여준다. 불교의 무상 개념을 바탕으로, 이 순환은 의미가 정적 분류가 아닌 지속적인 변화에서 발현됨을 시사한다.</p>
            
            <p class="exhibition-text">작품은 묻는다. 감정 인식 시스템은 무엇을 인식하는가? 표정을 범주로 번역하는 것은 이해인가, 환원인가? 그리고 우리는 알고리즘이 우리를 어떻게 보는지를 보면서, 우리 자신에 대해 무엇을 배우는가?</p>
        </div>
        
        <div class="exhibition-image-column">
            <!-- Right column - empty for now, will contain images later -->
        </div>
    </div>
</div>
