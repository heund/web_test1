**행동 기반 시스템 소니피케이션 (Behaviour-Driven Systemic Sonification)**

행동 기반 시스템 소니피케이션은 데이터를 정적 수치가 아닌 동적 시스템의 행동으로 모델링하는 데이터 변환 방법론이다. 이는 관계적 인지 시스템(RCS) 프레임워크의 구체적 구현 방식 중 하나로, 데이터 소니피케이션 영역에 특화되어 있다.


**기존 접근의 한계와 대안**


**파라미터 매핑의 특성**

보편적인 데이터 소니피케이션은 파라미터 매핑에 기반한다(Grond & Berger, 2011). 데이터 값을 음향 파라미터에 일대일 대응시킨다. 이 접근은 단순하고 직관적이지만, Grond와 Berger(2011)가 지적하듯 "고차원 데이터의 소니피케이션은 일관되고 직관적인 음향 결과를 보장할 청각 모델의 부재로 인해 제한된다."

구체적으로, 파라미터 매핑은 데이터의 현재 상태만 변환한다. 그 상태에 도달한 과정, 다른 변수들과의 관계, 시간에 따른 변화의 궤적은 포착되지 않는다. 데이터를 스냅샷으로 축소하며, 복잡한 시스템의 역동성은 사라진다.


**모델 기반 소니피케이션(Model-Based Sonification)과의 관계**

Hermann과 Ritter(1999, 2004)는 파라미터 매핑의 대안으로 모델 기반 소니피케이션을 제안했다. 이는 데이터를 가상의 소리 생성 가능 시스템으로 변환하고, 사용자가 이 시스템을 탐색하고 여기할 수 있도록 한다. 소리는 데이터셋의 속성과 사용자 상호작용의 특성 모두를 반영한다.

행동 기반 시스템 소니피케이션은 모델 기반 소니피케이션과 중요한 통찰을 공유한다. 둘 다 데이터를 정적 값이 아닌 동적 과정으로 다루며, 창발적 패턴을 의미 있는 것으로 본다. 파라미터 매핑이 데이터 값을 음향 파라미터에 직접 대응시키는 것과 달리, 두 접근 모두 데이터로부터 행동하는 시스템을 구축한다.

그러나 행동 기반 시스템 소니피케이션의 "시스템"은 다른 의미를 갖는다. 모델 기반 소니피케이션에서 시스템은 사용자가 탐색하는 단일 모델이다. 사용자가 시스템을 여기하고, 그 음향적 반응을 통해 데이터의 군집화나 위상적 구조를 이해한다. 행동 기반 시스템 소니피케이션에서 시스템은 다중 에이전트로 구성된 생태계다. 에이전트들은 자율적으로 협상하며, 이들 간 상호작용이 소리를 생성한다. 사용자 입력은 여기 신호가 아니라 이 생태계의 상태를 변화시키는 환경적 요인으로 작용한다.

또한, 모델 기반 소니피케이션은 주로 데이터 탐색과 분석을 위한 도구로 기능한다. 행동 기반 시스템 소니피케이션은 시스템 수준의 특성을 모델링한다. 긴장, 협상, 일관성이 그것이다. 개별 데이터 포인트의 기하학이 아니라, 시스템 전체가 어떻게 스트레스에 반응하고, 에이전트들이 어떻게 균형을 협상하며, 언제 임계점에 도달하는지를 드러낸다. 이는 에이전트 기반 협상과 동역학계 이론의 개념을 통합한 접근이다.


**핵심 개념: 데이터를 상태 공간으로**

행동 기반 시스템 소니피케이션은 데이터를 벡터 공간의 점으로 모델링한다. 각 축은 하나의 변수를 나타내며, 시스템의 현재 상태는 이 공간 내 특정 위치로 표현된다. 이 점은 시간에 따라 움직이며, 그 궤적이 시스템의 행동을 드러낸다.

이 공간 내에는 어트랙터 존이 정의된다. 동역학계 이론(Riley, 2012)에서 어트랙터는 시스템이 수렴하는 안정적 상태를 나타낸다. 중요한 점은, 이 어트랙터들이 고정된 범주가 아니라는 것이다. 퍼지 논리를 통해 부분적 소속과 전환을 허용한다. 시스템은 여러 어트랙터에 동시에 속할 수 있으며, 이 중첩된 상태가 협상의 공간을 만든다.

예를 들어, 식물 광합성 모델에서는 네 가지 어트랙터가 정의된다. 휴식, 회복, 스트레스, 위기가 그것이다. 환경 조건(광량, 온도, 수분)이 변화하면서 시스템은 이 어트랙터들 사이를 이동한다. 완전히 하나의 상태에 있거나, 여러 상태 사이의 전환 지점에 있을 수 있다.


**에이전트 기반 협상**

행동 기반 시스템 소니피케이션은 데이터 공간 내에서 작동하는 자율 에이전트들을 통해 협상을 모델링한다. 에이전트 기반 모델은 개별 규칙의 상호작용으로부터 창발적 시스템 행동을 생성할 수 있다(Bonabeau, 2002). 각 에이전트는 시스템 상태에 대한 서로 다른 관점을 갖고 있으며, 이들의 상호작용이 소리를 생성한다.

에이전트는 고정된 규칙에 따라 움직이지 않는다. 대신 끌림 값을 유지한다. 이는 시스템 상태에 대한 끌림과 반발을 나타내는 연속적으로 변화하는 값이다. 환경 입력, 다른 에이전트들의 상태, 그리고 시스템의 전체적 일관성에 따라 매 순간 재계산된다.

예를 들어, 식물 광합성 모델에서는 세 개의 에이전트가 작동한다. **에이전트 A**는 균형을 추구한다. 시스템이 안정 상태로 돌아가려는 경향을 모델링하며, 핵심 주파수를 설정한다. 그러나 이는 단순한 항상성이 아니다. 시스템적 긴장이 필요할 때는 균형 추구를 늦춘다. **에이전트 B**는 준비성을 나타낸다. 시스템이 얼마나 변화에 대응할 준비가 되어있는지를 추적하며, 스트레스와 일관성에 따라 행동 임계값을 조정한다. 화성 간격을 변조하는 역할을 맡는다. **에이전트 C**는 기억으로 작동한다. 이전에 발생한 중요한 시스템 변화를 기억하고, 필요할 때 에이전트 A와 B의 주파수를 반복하거나 상기시킨다. 이는 시스템이 과거 상태와의 관계 속에서 작동하도록 만든다.

에이전트들 간의 대화는 그래뉼러 합성 레이어로 렌더링된다. 벨 같은 입자들이 미시적 협상 역학을 나타낸다.


**전역 시스템 인식**

에이전트들의 국지적 협상을 넘어서, 시스템 전체의 상태를 평가하는 메커니즘이 필요하다. 전역 시스템 인식은 실시간으로 시스템의 일관성을 계산하는 고수준 모듈이다.

전역 시스템 인식은 모든 변수들의 상태, 어트랙터 소속도, 에이전트들의 긴장도를 종합해 단일 일관성 메트릭을 생성한다. 이 값은 시스템이 얼마나 안정적이고 조율되어 있는지를 나타낸다.

이 일관성 메트릭은 에이전트들의 행동을 유도할 수 있다. 예를 들어, 특정 구현에서는 일관성에 따라 화성 간격을 조정한다. 그러나 이는 하나의 가능한 매핑일 뿐이며, 시스템의 맥락과 목적에 따라 다른 방식으로 구현될 수 있다.

중요한 점은, 이러한 매핑이 사전에 프로그래밍된 시퀀스가 아니라는 것이다. 시스템의 협상 상태에 따라 실시간으로 결정된다. 소리는 시스템 상태를 표현하는 것이 아니라, 시스템 협상의 창발적 결과다.


**소리는 협상의 증거**

행동 기반 시스템 소니피케이션에서 소리는 디자인된 출력이 아니다. 소리는 진행 중인 협상의 증거다. 환경 압력과 내부 적응 과정 사이의 지속적 대화가 청각적으로 현현된 것이다.

이는 데이터 소니피케이션에 대한 근본적으로 다른 접근이다. 파라미터 매핑이 "이 데이터를 어떤 소리로 표현할까"를 묻는다면, 행동 기반 시스템 소니피케이션은 "이 시스템의 협상 과정이 어떤 소리를 만들어내는가"를 묻는다.

이 접근은 시스템의 복잡성을 축소하지 않고 보존한다. 파라미터 매핑은 다변수를 소수의 음향 파라미터로 압축한다. 반면 행동 기반 시스템 소니피케이션은 변수들 간 관계, 시간적 궤적, 전환 상태, 협상의 긴장을 모두 청각적으로 렌더링한다.


**참고문헌**

Bonabeau, E. (2002). Agent-based modeling: Methods and techniques for simulating human systems. PNAS, 99(suppl 3), 7280-7287.

Grond, F., & Berger, J. (2011). Parameter mapping sonification. In T. Hermann, A. Hunt, & J. G. Neuhoff (Eds.), The Sonification Handbook (pp. 363-397). Berlin: Logos Publishing House.

Hermann, T., & Ritter, H. (1999). Listen to your data: Model-based sonification for data analysis. In G. E. Lasker (Ed.), Advances in Intelligent Computing and Multimedia Systems (pp. 189-194). International Institute for Advanced Studies in System Research and Cybernetics.

Hermann, T., & Ritter, H. (2004). Model-based sonification revisited. In S. Barrass & P. Vickers (Eds.), Proceedings of the 10th International Conference on Auditory Display (ICAD 2004).

Riley, M. A. (2012). Dynamics of cognition. Wiley Interdisciplinary Reviews: Cognitive Science, 3(6), 593-606.