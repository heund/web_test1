<!-- ENGLISH VERSION -->
<div class="lang-en">
    <h2>Behaviour-Driven Systemic Sonification (BDSS)</h2>
    
    <div class="exhibition-content-wrapper">
        <div class="exhibition-text-column">
            <p class="exhibition-text">A sonification methodology modelling adaptive negotiation in complex systems through sound. BDSS conceptualises processes as trajectories within dynamic attractor spaces characterised by fuzzy, overlapping boundaries rather than discrete states. Agent-based layers simulate competing pressures, generating sonic textures that embody systemic tension, adaptation, and feedback.</p>
            
            <p class="exhibition-text">Sound functions as perceptual evidence of negotiation between internal and external forces, articulating how stability and change emerge through continuous relational adjustment. By treating sonification as expression of systemic behaviour rather than data translation, BDSS enables critical engagement with hidden dynamics through embodied listening.</p>
        </div>
    </div>
    
    <div class="process-images">
        <div class="image-item">
            <div class="image-label"><span class="prompt">></span> BDSS Prototype Implementation (Zenodo)</div>
            <a href="https://doi.org/10.5281/zenodo.15509042" target="_blank" style="color: var(--text-secondary); text-decoration: none;">doi.org/10.5281/zenodo.15509042</a>
        </div>
        <div class="image-item">
            <div class="image-label"><span class="prompt">></span> How a Leaf Sounds as a System</div>
            <a href="https://youtu.be/U3tuYjfow6o" target="_blank" style="color: var(--text-secondary); text-decoration: none;">youtu.be/U3tuYjfow6o</a>
        </div>
        <div class="image-item">
            <div class="image-label"><span class="prompt">></span> Photosynthesis as Generative Sound</div>
            <a href="https://youtu.be/TRb-llECHgI" target="_blank" style="color: var(--text-secondary); text-decoration: none;">youtu.be/TRb-llECHgI</a>
        </div>
        <div class="image-item">
            <div class="image-label"><span class="prompt">></span> Data-Driven Cross-Modal Sonification Engine</div>
            <a href="https://youtube.com/shorts/nCGHsyoMR84" target="_blank" style="color: var(--text-secondary); text-decoration: none;">youtube.com/shorts/nCGHsyoMR84</a>
        </div>
    </div>
</div>

<!-- KOREAN VERSION -->
<div class="lang-kr">
    <h2>행동 기반 시스템 소니피케이션<br>
        (Behaviour-Driven Systemic Sonification)</h2>
    
    <div class="exhibition-content-wrapper">
        <div class="exhibition-text-column">
            <p class="exhibition-text">행동 기반 시스템 소니피케이션은 데이터를 정적 수치가 아닌 동적 시스템의 행동으로 모델링하는 데이터 변환 방법론이다. 이는 관계적 인지 시스템(RCS) 프레임워크의 구체적 구현 방식 중 하나로, 데이터 소니피케이션 영역에 특화되어 있다.</p>
    <br>
    <h2>문제: 직접 매핑의 한계</h2>
    
    <p class="exhibition-text">보편적인 데이터 소니피케이션은 직접 매핑(direct mapping)에 기반한다. 데이터 값을 음향 파라미터에 일대일 대응시킨다. 온도가 높으면 주파수가 높아지고, 압력이 강하면 볼륨이 커진다. 이 접근은 단순하고 직관적이지만, 근본적 한계가 있다.</p>
    
    <p class="exhibition-text"><strong>첫째</strong>, 데이터의 현재 상태만 변환한다. 그 상태에 도달한 과정, 다른 변수들과의 관계, 시간에 따른 변화의 궤적은 포착되지 않는다.</p>
    
    <p class="exhibition-text"><strong>둘째</strong>, 데이터를 스냅샷으로 축소한다. 복잡한 시스템의 역동성은 사라지고, 순간적 수치만 남는다.</p>
    
    <p class="exhibition-text"><strong>셋째</strong>, 변환 과정에서 관계가 소실된다. 다변수 시스템에서 중요한 것은 개별 변수의 값이 아니라 변수들 간 상호작용이다. 직접 매핑은 이를 포착할 수 없다.</p>
    
    <h2>핵심 개념: 데이터를 상태 공간으로</h2>
    
    <p class="exhibition-text">행동 기반 시스템 소니피케이션은 데이터를 벡터 공간의 점으로 모델링한다. 각 축은 하나의 변수를 나타내며, 시스템의 현재 상태는 이 공간 내 특정 위치로 표현된다. 이 점은 시간에 따라 움직이며, 그 궤적이 시스템의 행동을 드러낸다.</p>
    
    <p class="exhibition-text">이 공간 내에는 어트랙터 존(attractor zones)이 정의된다. 이는 시스템이 특정 상태에 머무르려는 경향을 나타낸다. 중요한 점은, 이 어트랙터들이 고정된 범주가 아니라는 것이다. 퍼지 로직(fuzzy logic)을 통해 부분적 멤버십과 전환을 허용한다. 시스템은 여러 어트랙터에 동시에 속할 수 있으며, 이 중첩된 상태가 협상의 공간을 만든다.</p>
    
    <p class="exhibition-text">예를 들어, 식물 광합성 모델에서는 네 가지 어트랙터가 정의된다: Rest, Recovery, Stress, Critical. 환경 조건(광량, 온도, 수분)이 변화하면서 시스템은 이 어트랙터들 사이를 이동한다. 완전히 하나의 상태에 있거나, 여러 상태 사이의 전환 지점에 있을 수 있다.</p>
    
    <h2>에이전트 기반 협상</h2>
    
    <p class="exhibition-text">행동 기반 시스템 소니피케이션은 데이터 공간 내에서 작동하는 자율 에이전트들을 통해 협상을 모델링한다. 각 에이전트는 시스템 상태에 대한 서로 다른 관점을 갖고 있으며, 이들의 상호작용이 소리를 생성한다.</p>
    
    <p class="exhibition-text">에이전트는 고정된 규칙에 따라 움직이지 않는다. 대신 pull value를 유지한다. 이는 시스템 상태에 대한 끌림과 반발을 나타내는 연속적으로 변화하는 값이다. 환경 입력, 다른 에이전트들의 상태, 그리고 시스템의 전체적 일관성에 따라 매 순간 재계산된다.</p>
    
    <p class="exhibition-text">예를 들어, 식물 광합성 모델에서는 세 개의 에이전트가 작동한다.</p>
    
    <ul class="exhibition-list">
        <li><strong>Agent A</strong>는 균형을 추구한다. 시스템이 안정 상태로 돌아가려는 경향을 모델링하며, 핵심 주파수를 설정한다. 그러나 이는 단순한 항상성(homeostasis)이 아니다. 시스템적 긴장이 필요할 때는 균형 추구를 늦춘다.</li>
        <li><strong>Agent B</strong>는 준비성(readiness)을 나타낸다. 시스템이 얼마나 변화에 대응할 준비가 되어있는지를 추적하며, 스트레스와 일관성에 따라 행동 임계값을 조정한다. 화성 간격(harmonic interval)을 변조하는 역할을 맡는다.</li>
        <li><strong>Agent C</strong>는 기억으로 작동한다. 이전에 발생한 중요한 시스템 변화를 기억하고, 필요할 때 Agent A와 B의 주파수를 반복하거나 상기시킨다. 이는 시스템이 과거 상태와의 관계 속에서 작동하도록 만든다.</li>
    </ul>
    
    <p class="exhibition-text">에이전트들 간의 대화는 그래뉼러 신스(granular synthesis) 레이어로 렌더링된다. 벨 같은 그레인(grain)들이 미시적 협상 역학을 나타낸다. 이는 에이전트들이 어떻게 서로에게 반응하고, 조율하며, 때로는 충돌하는지를 청각적으로 드러낸다.</p>
    
    <h2>전역 시스템 인식</h2>
    
    <p class="exhibition-text">에이전트들의 국지적 협상을 넘어서, 시스템 전체의 상태를 평가하는 메커니즘이 필요하다. 전역 시스템 인식(Global System Awareness, GSA)은 실시간으로 시스템의 일관성을 계산하는 고수준 모듈이다.</p>
    
    <p class="exhibition-text">GSA는 모든 변수들의 상태, 어트랙터 멤버십, 에이전트들의 긴장도를 종합해 단일 일관성 메트릭을 생성한다. 이 값은 시스템이 얼마나 안정적이고 조율되어 있는지를 나타낸다.</p>
    
    <p class="exhibition-text">이 일관성 메트릭은 에이전트들의 행동을 유도할 수 있다. 예를 들어, 특정 구현에서는 일관성에 따라 화성 간격을 조정한다. 높은 일관성일 때 협화음 간격을, 중간 일관성에서 중간 정도의 간격을, 낮은 일관성에서 불협화음 간격을 사용하는 방식이다. 그러나 이는 하나의 가능한 매핑일 뿐이며, 시스템의 맥락과 목적에 따라 다른 방식으로 구현될 수 있다.</p>
    
    <p class="exhibition-text">중요한 점은, 이러한 매핑이 사전에 프로그래밍된 시퀀스가 아니라는 것이다. 시스템의 협상 상태에 따라 실시간으로 결정된다. 소리는 시스템 상태를 표현하는 것이 아니라, 시스템 협상의 창발적 결과다.</p>
    
    <h2>소리는 협상의 증거</h2>
    
    <p class="exhibition-text">행동 기반 시스템 소니피케이션에서 소리는 디자인된 출력이 아니다. 소리는 진행 중인 협상의 증거다. 환경 압력과 내부 적응 과정 사이의 지속적 대화가 청각적으로 현현된 것이다.</p>
    
    <p class="exhibition-text">이는 데이터 소니피케이션에 대한 근본적으로 다른 접근이다. 전통적 방법이 "이 데이터를 어떤 소리로 표현할까"를 묻는다면, 행동 기반 시스템 소니피케이션은 "이 시스템의 협상 과정이 어떤 소리를 만들어내는가"를 묻는다.</p>
    
    <p class="exhibition-text">데이터는 더 이상 변환의 대상이 아니다. 데이터는 행동하는 엔티티들이 작동하는 환경이다. 에이전트들은 이 환경에 반응하고, 서로 협상하며, 시간에 따라 궤적을 형성한다. 소리는 이 과정의 부산물이 아니라 본질적 표현이다.</p>
    
    <p class="exhibition-text">이 접근은 또한 시스템의 복잡성을 축소하지 않고 보존한다. 직접 매핑은 다변수를 소수의 음향 파라미터로 압축한다. 반면 행동 기반 시스템 소니피케이션은 변수들 간 관계, 시간적 궤적, 전환 상태, 협상의 긴장을 모두 청각적으로 렌더링한다.</p>
    
    <h2>방법론으로서의 BDSS</h2>
    
    <p class="exhibition-text">행동 기반 시스템 소니피케이션은 관계적 인지 시스템 프레임워크를 데이터 변환 영역에 적용한 방법론이다. 이는 RCS의 핵심 원리들을 구체적으로 실행한다.</p>
    
    <ul class="exhibition-list">
        <li><strong>관계적 창발</strong>: 소리는 개별 데이터 포인트가 아니라 에이전트들 간 상호작용에서 창발한다.</li>
        <li><strong>협상 기반 일관성</strong>: 시스템은 최적값을 찾지 않고, 에이전트들이 지속적으로 협상하며 일관성을 추구한다.</li>
        <li><strong>재귀적 피드백</strong>: 에이전트들의 출력은 다시 시스템 상태에 영향을 미치며, 순환 구조를 형성한다.</li>
        <li><strong>범주화 거부</strong>: 어트랙터 존은 고정된 범주가 아니라 퍼지 멤버십을 허용하며, 전환 상태를 명시적으로 모델링한다.</li>
        <li><strong>시간적 서사</strong>: 데이터는 순간적 값이 아니라 시간에 따라 전개되는 궤적으로 접근된다.</li>
    </ul>
    
    <p class="exhibition-text">이 방법론은 데이터 소니피케이션을 넘어 다양한 데이터 변환 맥락에 적용 가능하다. 시각화, 촉각 피드백, 멀티모달 인터페이스. 핵심은 데이터를 숫자가 아닌 행동으로, 상태가 아닌 과정으로, 결과가 아닌 협상으로 다루는 것이다.</p>
        </div>
    </div>
    
    <div class="process-images">
        <div class="image-item">
            <div class="image-label"><span class="prompt">></span> BDSS Prototype Implementation (Zenodo)</div>
            <a href="https://doi.org/10.5281/zenodo.15509042" target="_blank" style="color: var(--text-secondary); text-decoration: none;">doi.org/10.5281/zenodo.15509042</a>
        </div>
        <div class="image-item">
            <div class="image-label"><span class="prompt">></span> How a Leaf Sounds as a System</div>
            <a href="https://youtu.be/U3tuYjfow6o" target="_blank" style="color: var(--text-secondary); text-decoration: none;">youtu.be/U3tuYjfow6o</a>
        </div>
        <div class="image-item">
            <div class="image-label"><span class="prompt">></span> Photosynthesis as Generative Sound</div>
            <a href="https://youtu.be/TRb-llECHgI" target="_blank" style="color: var(--text-secondary); text-decoration: none;">youtu.be/TRb-llECHgI</a>
        </div>
        <div class="image-item">
            <div class="image-label"><span class="prompt">></span> Data-Driven Cross-Modal Sonification Engine</div>
            <a href="https://youtube.com/shorts/nCGHsyoMR84" target="_blank" style="color: var(--text-secondary); text-decoration: none;">youtube.com/shorts/nCGHsyoMR84</a>
        </div>
    </div>
</div>
